I am downloading and running the meta-llama/Llama-3.2-1B model locally via GoogleColab.

This is a jupyter notebook of the logic for future reference
